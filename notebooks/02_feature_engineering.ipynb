{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5724248a-f449-4f21-b7d5-dd6f72a8893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded successfully!\n",
      "ğŸ“Š Original dataset shape: (284807, 31)\n",
      "   284,807 transactions, 31 features\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load original data\n",
    "df = pd.read_csv('../data/creditcard.csv')\n",
    "print(\"âœ… Data loaded successfully!\")\n",
    "print(f\"ğŸ“Š Original dataset shape: {df.shape}\")\n",
    "print(f\"   {df.shape[0]:,} transactions, {df.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19b0ff1-0f51-4e0b-aa74-177ea764f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ• CREATING TIME-BASED FEATURES\n",
      "============================================================\n",
      "âœ… Created features:\n",
      "   - Hour: Hour of day (0-23)\n",
      "   - Day: Day number since start\n",
      "\n",
      "ğŸ“Š Time range in dataset:\n",
      "   First transaction: 0.0 seconds (Day 0, Hour 0)\n",
      "   Last transaction: 172792.0 seconds (Day 1, Hour 24.0)\n",
      "\n",
      "ğŸ“ Example transformation:\n",
      "   Time      Hour  Day\n",
      "0   0.0  0.000000    0\n",
      "1   0.0  0.000000    0\n",
      "2   1.0  0.000278    0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Create time-based features\n",
    "print(\"ğŸ• CREATING TIME-BASED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Time is in seconds - convert to hours and days\n",
    "df['Hour'] = (df['Time'] / 3600) % 24  # Hour of day (0-23)\n",
    "df['Day'] = (df['Time'] / 86400).astype(int)  # Day number (0, 1, 2...)\n",
    "\n",
    "print(\"âœ… Created features:\")\n",
    "print(\"   - Hour: Hour of day (0-23)\")\n",
    "print(\"   - Day: Day number since start\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Time range in dataset:\")\n",
    "print(f\"   First transaction: {df['Time'].min()} seconds (Day 0, Hour 0)\")\n",
    "print(f\"   Last transaction: {df['Time'].max()} seconds (Day {df['Day'].max()}, Hour {df['Hour'].iloc[-1]:.1f})\")\n",
    "\n",
    "# Show example\n",
    "print(f\"\\nğŸ“ Example transformation:\")\n",
    "sample = df[['Time', 'Hour', 'Day']].head(3)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5170d491-e592-410c-ae7f-f92ce098c917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’° CREATING AMOUNT-BASED FEATURES\n",
      "============================================================\n",
      "âœ… Created features:\n",
      "   - Amount_log: Log-transformed amount (handles outliers)\n",
      "   - Amount_squared: Polynomial feature (non-linear patterns)\n",
      "   - Amount_category: Categorized amounts (0=Small, 1=Medium, 2=Large, 3=Very Large)\n",
      "\n",
      "ğŸ“Š Amount feature statistics:\n",
      "   Original Amount - Mean: $88.35, Max: $25691.16\n",
      "   Log Amount - Mean: 3.15, Max: 10.15\n",
      "\n",
      "ğŸ“ Example transformation:\n",
      "   Amount  Amount_log  Amount_squared  Amount_category\n",
      "0  149.62    5.014760      22386.1444                1\n",
      "1    2.69    1.305626          7.2361                0\n",
      "2  378.66    5.939276     143383.3956                2\n",
      "3  123.50    4.824306      15252.2500                1\n",
      "4   69.99    4.262539       4898.6001                1\n",
      "\n",
      "âœ… New dataset shape: (284807, 36)\n",
      "   Added 5 new features!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create amount-based features\n",
    "print(\"ğŸ’° CREATING AMOUNT-BASED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Log transformation (handles outliers and skewness)\n",
    "df['Amount_log'] = np.log1p(df['Amount'])  # log(1 + Amount) to handle zeros\n",
    "\n",
    "# Polynomial feature (captures non-linear relationships)\n",
    "df['Amount_squared'] = df['Amount'] ** 2\n",
    "\n",
    "# Categorize amounts into bins\n",
    "df['Amount_category'] = pd.cut(df['Amount'], \n",
    "                                bins=[0, 50, 150, 500, df['Amount'].max()],\n",
    "                                labels=['Small', 'Medium', 'Large', 'Very_Large'])\n",
    "df['Amount_category'] = df['Amount_category'].astype('category').cat.codes\n",
    "\n",
    "print(\"âœ… Created features:\")\n",
    "print(\"   - Amount_log: Log-transformed amount (handles outliers)\")\n",
    "print(\"   - Amount_squared: Polynomial feature (non-linear patterns)\")\n",
    "print(\"   - Amount_category: Categorized amounts (0=Small, 1=Medium, 2=Large, 3=Very Large)\")\n",
    "\n",
    "# Show statistics\n",
    "print(f\"\\nğŸ“Š Amount feature statistics:\")\n",
    "print(f\"   Original Amount - Mean: ${df['Amount'].mean():.2f}, Max: ${df['Amount'].max():.2f}\")\n",
    "print(f\"   Log Amount - Mean: {df['Amount_log'].mean():.2f}, Max: {df['Amount_log'].max():.2f}\")\n",
    "\n",
    "# Show example\n",
    "print(f\"\\nğŸ“ Example transformation:\")\n",
    "sample = df[['Amount', 'Amount_log', 'Amount_squared', 'Amount_category']].head(5)\n",
    "print(sample)\n",
    "\n",
    "print(f\"\\nâœ… New dataset shape: {df.shape}\")\n",
    "print(f\"   Added {df.shape[1] - 31} new features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af59975-e241-4728-8615-e3cc72fc649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ PREPARING FEATURES FOR MODELING\n",
      "============================================================\n",
      "âœ… Separated data:\n",
      "   Features (X): (284807, 35)\n",
      "   Target (y): (284807,)\n",
      "\n",
      "ğŸ“ Features to be scaled: 6\n",
      "   - Time\n",
      "   - Amount\n",
      "   - Hour\n",
      "   - Day\n",
      "   - Amount_log\n",
      "   - Amount_squared\n",
      "\n",
      "ğŸ“Š Before scaling - sample values:\n",
      "   Time  Amount      Hour  Day  Amount_log  Amount_squared\n",
      "0   0.0  149.62  0.000000    0    5.014760      22386.1444\n",
      "1   0.0    2.69  0.000000    0    1.305626          7.2361\n",
      "2   1.0  378.66  0.000278    0    5.939276     143383.3956\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Prepare features for modeling\n",
    "print(\"ğŸ¯ PREPARING FEATURES FOR MODELING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(['Class'], axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "print(f\"âœ… Separated data:\")\n",
    "print(f\"   Features (X): {X.shape}\")\n",
    "print(f\"   Target (y): {y.shape}\")\n",
    "\n",
    "# Identify features that need scaling\n",
    "# V1-V28 are already scaled (PCA transformed)\n",
    "# We need to scale: Time, Amount, Hour, Day, and new amount features\n",
    "features_to_scale = ['Time', 'Amount', 'Hour', 'Day', 'Amount_log', 'Amount_squared']\n",
    "\n",
    "print(f\"\\nğŸ“ Features to be scaled: {len(features_to_scale)}\")\n",
    "for feat in features_to_scale:\n",
    "    print(f\"   - {feat}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Before scaling - sample values:\")\n",
    "print(X[features_to_scale].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d56131-b4c7-4ee8-bf61-30457309d0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš–ï¸ SCALING FEATURES\n",
      "============================================================\n",
      "âœ… Features scaled using StandardScaler\n",
      "   (Transformed to mean=0, standard deviation=1)\n",
      "\n",
      "ğŸ“Š After scaling - sample values:\n",
      "       Time    Amount      Hour       Day  Amount_log  Amount_squared\n",
      "0 -1.996583  0.244964 -2.486373 -0.983407    1.124303       -0.025978\n",
      "1 -1.996583 -0.342475 -2.486373 -0.983407   -1.114639       -0.038095\n",
      "2 -1.996562  1.160686 -2.486326 -0.983407    1.682368        0.039535\n",
      "\n",
      "ğŸ“ˆ Scaling verification:\n",
      "   Time: mean=-0.000000, std=1.000002\n",
      "   Amount: mean=-0.000000, std=1.000002\n",
      "   Hour: mean=0.000000, std=1.000002\n",
      "   Day: mean=0.000000, std=1.000002\n",
      "   Amount_log: mean=0.000000, std=1.000002\n",
      "   Amount_squared: mean=0.000000, std=1.000002\n",
      "\n",
      "ğŸ’¡ Note: Values close to 0 mean = good scaling!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Scale features\n",
    "print(\"âš–ï¸ SCALING FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize scaler (StandardScaler: mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the specified features\n",
    "X[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n",
    "\n",
    "print(\"âœ… Features scaled using StandardScaler\")\n",
    "print(\"   (Transformed to mean=0, standard deviation=1)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š After scaling - sample values:\")\n",
    "print(X[features_to_scale].head(3))\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Scaling verification:\")\n",
    "for feat in features_to_scale:\n",
    "    print(f\"   {feat}: mean={X[feat].mean():.6f}, std={X[feat].std():.6f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Note: Values close to 0 mean = good scaling!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485b6833-a72e-40f4-9bf0-38fc01ceefa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ SPLITTING DATA: TRAIN vs TEST\n",
      "============================================================\n",
      "âœ… Data split completed:\n",
      "\n",
      "ğŸ“š Training Set:\n",
      "   Total transactions: 199,364\n",
      "   Frauds: 344 (0.173%)\n",
      "   Normal: 199,020 (99.827%)\n",
      "\n",
      "ğŸ§ª Test Set:\n",
      "   Total transactions: 85,443\n",
      "   Frauds: 148 (0.173%)\n",
      "   Normal: 85,295 (99.827%)\n",
      "\n",
      "ğŸ’¡ Stratified split ensures fraud ratio is same in both sets!\n",
      "   This is CRITICAL for imbalanced datasets.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Train-test split\n",
    "print(\"âœ‚ï¸ SPLITTING DATA: TRAIN vs TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Split with stratification (maintains fraud ratio in both sets)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3,        # 30% for testing\n",
    "    random_state=42,      # Reproducible results\n",
    "    stratify=y            # Keep fraud ratio same in train and test\n",
    ")\n",
    "\n",
    "print(f\"âœ… Data split completed:\")\n",
    "print(f\"\\nğŸ“š Training Set:\")\n",
    "print(f\"   Total transactions: {len(X_train):,}\")\n",
    "print(f\"   Frauds: {y_train.sum():,} ({y_train.sum()/len(y_train)*100:.3f}%)\")\n",
    "print(f\"   Normal: {len(y_train) - y_train.sum():,} ({(len(y_train) - y_train.sum())/len(y_train)*100:.3f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ§ª Test Set:\")\n",
    "print(f\"   Total transactions: {len(X_test):,}\")\n",
    "print(f\"   Frauds: {y_test.sum():,} ({y_test.sum()/len(y_test)*100:.3f}%)\")\n",
    "print(f\"   Normal: {len(y_test) - y_test.sum():,} ({(len(y_test) - y_test.sum())/len(y_test)*100:.3f}%)\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Stratified split ensures fraud ratio is same in both sets!\")\n",
    "print(\"   This is CRITICAL for imbalanced datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474b8ade-a507-4a0d-b792-6b975d61129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ SAVING PROCESSED DATA\n",
      "============================================================\n",
      "âœ… Files saved successfully:\n",
      "   âœ“ ../data/X_train.csv\n",
      "   âœ“ ../data/X_test.csv\n",
      "   âœ“ ../data/y_train.csv\n",
      "   âœ“ ../data/y_test.csv\n",
      "   âœ“ ../data/processed_full_data.csv (full dataset with new features)\n",
      "\n",
      "ğŸ“Š Summary of saved data:\n",
      "   Training set: 199,364 transactions Ã— 35 features\n",
      "   Test set: 85,443 transactions Ã— 35 features\n",
      "\n",
      "ğŸ‰ PHASE 2 COMPLETE!\n",
      "============================================================\n",
      "Next up: Phase 3 - Building Machine Learning Models! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Save processed data\n",
    "print(\"ğŸ’¾ SAVING PROCESSED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save to CSV files\n",
    "X_train.to_csv('../data/X_train.csv', index=False)\n",
    "X_test.to_csv('../data/X_test.csv', index=False)\n",
    "y_train.to_csv('../data/y_train.csv', index=False)\n",
    "y_test.to_csv('../data/y_test.csv', index=False)\n",
    "\n",
    "print(\"âœ… Files saved successfully:\")\n",
    "print(\"   âœ“ ../data/X_train.csv\")\n",
    "print(\"   âœ“ ../data/X_test.csv\")\n",
    "print(\"   âœ“ ../data/y_train.csv\")\n",
    "print(\"   âœ“ ../data/y_test.csv\")\n",
    "\n",
    "# Also save the full processed dataset (optional, for reference)\n",
    "df.to_csv('../data/processed_full_data.csv', index=False)\n",
    "print(\"   âœ“ ../data/processed_full_data.csv (full dataset with new features)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Summary of saved data:\")\n",
    "print(f\"   Training set: {X_train.shape[0]:,} transactions Ã— {X_train.shape[1]} features\")\n",
    "print(f\"   Test set: {X_test.shape[0]:,} transactions Ã— {X_test.shape[1]} features\")\n",
    "\n",
    "print(\"\\nğŸ‰ PHASE 2 COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"Next up: Phase 3 - Building Machine Learning Models! ğŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea18cc-0bec-45df-bc5f-1464046e66ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
